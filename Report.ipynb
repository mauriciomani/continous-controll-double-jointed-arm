{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "### 1. Start the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```\n",
    "I have already downloded the unity enviroment and place it same location as this file, once donde that you can access trough:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='Reacher_Linux/Reacher.x86')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Size of each action: 4\n",
      "There are 1 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726671e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "The cell below is just to give you an idea on how to make steps\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My implementation\n",
    "## Actor Critic Algorithms\n",
    "For infinite input space and infinite output space. Compared to Deep-Q that only allows a finite number of inputs, we have chosen Deep Deterministic Policy Gradient.\n",
    "#### Deep Deterministic Policy Gradient\n",
    "Used for continous action space, we have added noise to the process just like the authors did [Lillicrap et al, 2015](https://arxiv.org/pdf/1509.02971.pdf).\n",
    "\n",
    "### Use two separate models\n",
    "* One outputs the desire action in the continous space\n",
    "* Other an action to produce Q-values\n",
    "\n",
    "#### Actor Critic Methods is about having two models:\n",
    "Actor  takes current enviroment state and determines the best action to take from there. Critic takes in state and action and return score of how good the action is.\n",
    "\n",
    "#### Here is the code for Actor and Critic Network:\n",
    "Same architecture for both Agent and Critic with 2 fully connected layers of 400 and 300 units respectively, where values are normalized each batch. Activations are RELU on the first two layers for both Networks and then Tanh and no acytivation function respectively.\n",
    "\n",
    "#### Hyperparameters\n",
    "* fc1_units=400 \n",
    "* fc2_units=300 \n",
    "* BUFFER_SIZE = 100000  \n",
    "* BATCH_SIZE = 64     \n",
    "* GAMMA = 0.9          \n",
    "* TAU = 1e-4             \n",
    "* lr_actor = 1e-4        \n",
    "* lr_critic = 1e-4       \n",
    "* WEIGHT_DECAY = 0       \n",
    "* LEARN_EVERY = 20       \n",
    "* learning_num = 10      \n",
    "* GRAD_CLIPPING = 1.0    \n",
    "* ou_sigma = 0.2\n",
    "* ou_theta = 0.15\n",
    "* EPSILON = 1.0  \n",
    "* EPSILON_DECAY = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "import torch \n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "class Actor(nn.Module):\n",
      "    \"\"\"Actor\"\"\"\n",
      "    \n",
      "    def __init__(self, state_size, action_size, seed, fc1_units=400, fc2_units=300):\n",
      "        \"\"\"\n",
      "        Using two fully connected layers with 400 and 300 units respectively. Not resetting parameters.\n",
      "        \"\"\"\n",
      "        super(Actor, self).__init__()\n",
      "        #use for \n",
      "        self.seed = torch.manual_seed(seed)\n",
      "        #for fully connected layer input\n",
      "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
      "        #Applying batch normalization\n",
      "        self.bn1 = nn.BatchNorm1d(fc1_units)\n",
      "        #fully connected layers\n",
      "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
      "        self.fc3 =  nn.Linear(fc2_units, action_size)\n",
      "        \n",
      "    def forward(self, state):\n",
      "        \"\"\"Actor policy network to map states to actions, using relus and tahn\"\"\"\n",
      "        x = F.relu(self.bn1(self.fc1(state)))\n",
      "        x = F.relu(self.fc2(x))\n",
      "        return torch.tanh(self.fc3(x))\n",
      "    \n",
      "class Critic(nn.Module):\n",
      "    \"\"\"Critic\"\"\"\n",
      "    def __init__(self, state_size, action_size, seed, fc1_units=400, fc2_units=300):\n",
      "        \"\"\"Using same architecture as in Actor network. Two fully connected layers of 400 and 300 units respectively.\n",
      "        \"\"\"\n",
      "        super(Critic, self).__init__()\n",
      "        self.seed = torch.manual_seed(seed)\n",
      "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
      "        self.bn1 = nn.BatchNorm1d(fc1_units)\n",
      "        #in forward function action will be concatenated according to DDGP \n",
      "        self.fc2 = nn.Linear(fc1_units+action_size, fc2_units)\n",
      "        self.fc3 = nn.Linear(fc2_units, 1)\n",
      "        \n",
      "    def forward(self, state, action):\n",
      "        \"\"\"Critic value network that maps (state,action) pairs to Q-values\"\"\"\n",
      "        x = F.relu(self.bn1(self.fc1(state)))\n",
      "        #to concatenate action\n",
      "        x = torch.cat((x, action), dim=1)\n",
      "        x = F.relu(self.fc2(x))\n",
      "        return self.fc3(x)"
     ]
    }
   ],
   "source": [
    "! cat model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from collections import namedtuple, deque\n",
      "import torch\n",
      "import torch.nn.functional as F\n",
      "import torch.optim as optim\n",
      "import numpy as np\n",
      "import random\n",
      "from model import Actor, Critic\n",
      "import copy\n",
      "\n",
      "BUFFER_SIZE = 100000  # replay buffer\n",
      "BATCH_SIZE = 64       # batch size: fixed batch per pass\n",
      "GAMMA = 0.9           # discount factor\n",
      "TAU = 1e-4             # for soft update: Not update at once but frequently https://arxiv.org/pdf/1509.02971.pdf\n",
      "lr_actor = 1e-4        # learning rate actor\n",
      "lr_critic = 1e-4       # learning rate critic\n",
      "WEIGHT_DECAY = 0       # L2 weight decay\n",
      "\n",
      "LEARN_EVERY = 20       # learning timestep interval\n",
      "learning_num = 10         # number of learning passes\n",
      "GRAD_CLIPPING = 1.0    # gradient clipping \n",
      "\n",
      "# Ornstein-Uhlenbeck: Stochastic stationary Gauss-Markov process\n",
      "ou_sigma = 0.2\n",
      "ou_theta = 0.15\n",
      "\n",
      "EPSILON = 1.0  \n",
      "EPSILON_DECAY = 1e-6\n",
      "\n",
      "#gpu if possible\n",
      "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "\n",
      "class Agent():\n",
      "    \n",
      "    def __init__(self, state_size, action_size, seed=12):\n",
      "        \n",
      "        self.state_size = state_size\n",
      "        self.action_size = action_size\n",
      "        self.seed = random.seed(seed)\n",
      "        \n",
      "        self.epsilon = EPSILON\n",
      "        \n",
      "        #This the actor network. Imported from model.py\n",
      "        self.actor_local = Actor(state_size, action_size, seed).to(device)\n",
      "        self.actor_target = Actor(state_size, action_size, seed).to(device)\n",
      "        self.actor_optimizer = optim.Adam(self.actor_local.parameters(), lr=lr_actor)\n",
      "        \n",
      "        #We will test the critic to see how good is the action. Imported from model.py\n",
      "        self.critic_local = Critic(state_size, action_size, seed).to(device)\n",
      "        self.critic_target = Critic(state_size, action_size, seed).to(device)\n",
      "        self.critic_optimizer = optim.Adam(self.critic_local.parameters(), lr=lr_critic, weight_decay=WEIGHT_DECAY)\n",
      "        \n",
      "        # From class UONoise\n",
      "        self.noise = OUNoise(action_size, seed)\n",
      "        \n",
      "        # From class replay buffer\n",
      "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed)\n",
      "        \n",
      "        \n",
      "    def step(self, state, action, reward, next_state, done, timestep):\n",
      "        \"\"\"Save experience in replay buffer, and use sample from buffer to learn\"\"\"\n",
      "        \n",
      "        #from add function in Replay Buffer class: store experience\n",
      "        self.memory.add(state, action, reward, next_state, done)\n",
      "        \n",
      "        # If having enough batch size\n",
      "        if len(self.memory) > BATCH_SIZE and timestep % LEARN_EVERY == 0:\n",
      "            for _ in range(learning_num):\n",
      "                #sample data from sample function Replay Buffer class\n",
      "                experiences = self.memory.sample()\n",
      "                #from learn function\n",
      "                self.learn(experiences, GAMMA)\n",
      "                \n",
      "    def act(self, state):\n",
      "        \"\"\"Returns actions for given state as per current policy\"\"\"\n",
      "        #make state input\n",
      "        state = torch.from_numpy(state).float().to(device)\n",
      "        #in eval mode instead of trainning\n",
      "        self.actor_local.eval()\n",
      "        #do not save backprop but increase speed\n",
      "        with torch.no_grad():\n",
      "            action = self.actor_local(state).cpu().data.numpy()\n",
      "        #train actor\n",
      "        self.actor_local.train()\n",
      "        \n",
      "        #from sample noise class\n",
      "        action += self.epsilon * self.noise.sample()\n",
      "        \n",
      "        return np.clip(action, -1, 1)\n",
      "    \n",
      "    def reset(self):\n",
      "        \"\"\" Reset from Noise to mean\"\"\"\n",
      "        self.noise.reset()\n",
      "        \n",
      "    def learn(self, experiences, gamma):\n",
      "        \"\"\"\n",
      "        Experience is a tuple of states, actions, rewards, next_states, dones\n",
      "        Update policy and value parameters using given batch of experience tuples.\n",
      "        Q_targets = r + γ * critic_target(next_state, actor_target(next_state))\n",
      "        \"\"\"\n",
      "        \n",
      "        states, actions, rewards, next_states, dones = experiences\n",
      "        \n",
      "        #use target models\n",
      "        actions_next = self.actor_target(next_states)\n",
      "        #to feed critic we use actor actions\n",
      "        Q_targets_next = self.critic_target(next_states, actions_next)\n",
      "        # compute Q targets\n",
      "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
      "        # critic loss\n",
      "        Q_expected = self.critic_local(states, actions)\n",
      "        critic_loss = F.mse_loss(Q_expected, Q_targets)\n",
      "        # minimize critic the loss\n",
      "        self.critic_optimizer.zero_grad()\n",
      "        critic_loss.backward()\n",
      "        # gradient clipping for critic\n",
      "        if GRAD_CLIPPING > 0:\n",
      "            torch.nn.utils.clip_grad_norm_(self.critic_local.parameters(), GRAD_CLIPPING)\n",
      "        #step updates the parameter\n",
      "        self.critic_optimizer.step()\n",
      "        \n",
      "        # actor\n",
      "        actions_pred = self.actor_local(states)\n",
      "        actor_loss = -self.critic_local(states, actions_pred).mean()\n",
      "        # minimize the loss\n",
      "        self.actor_optimizer.zero_grad()\n",
      "        actor_loss.backward()\n",
      "        self.actor_optimizer.step()\n",
      "        \n",
      "        # update from soft_update function\n",
      "        self.soft_update(self.critic_local, self.critic_target, TAU)\n",
      "        self.soft_update(self.actor_local, self.actor_target, TAU)\n",
      "        # update epsilon decay\n",
      "        if EPSILON_DECAY > 0:\n",
      "            self.epsilon -= EPSILON_DECAY\n",
      "            self.noise.reset()\n",
      "            \n",
      "    def soft_update(self, local_model, target_model, tau):\n",
      "        \"\"\"Soft update model parameters. θ = τ*θ_local + (1 - τ)*θ_target\"\"\"  \n",
      "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
      "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
      "            \n",
      "class OUNoise:\n",
      "    \"\"\"Ornsten-Uhlenbeck\"\"\"\n",
      "    \n",
      "    def __init__(self, size, seed, mu=0., theta=ou_theta, sigma=ou_sigma):\n",
      "        #array of ones\n",
      "        self.mu = np.array(mu * size)\n",
      "        self.theta = theta\n",
      "        self.sigma = sigma\n",
      "        self.seed = random.seed(seed)\n",
      "        self.size = size\n",
      "        self.reset()\n",
      "        \n",
      "    def reset(self):\n",
      "        \"\"\"Return a shallow copy of x\"\"\"\n",
      "        self.state = copy.copy(self.mu)\n",
      "        \n",
      "    def sample(self):\n",
      "        \"\"\"Update internal state and return it as a noise sample\"\"\"\n",
      "        state = self.state\n",
      "        d_x = self.theta * (self.mu - state) + self.sigma * np.random.standard_normal(self.size)\n",
      "        self.state = state + d_x\n",
      "        return self.state\n",
      "    \n",
      "    \n",
      "class ReplayBuffer:\n",
      "    \"\"\"Store experience tuples.\"\"\"\n",
      "    \n",
      "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
      "        self.action_size = action_size\n",
      "        #Deque (Doubly Ended Queue)\n",
      "        self.memory = deque(maxlen=buffer_size) \n",
      "        #size of each training\n",
      "        self.batch_size = batch_size\n",
      "        self.experience = namedtuple(\"Experience\", field_names = [\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
      "        self.seed = random.seed(seed)\n",
      "        \n",
      "    def add(self, state, action, reward, next_state, done):\n",
      "        \"\"\"Add new experience to memory.\"\"\"\n",
      "        e = self.experience(state, action, reward, next_state, done)\n",
      "        self.memory.append(e)\n",
      "        \n",
      "    def sample(self):\n",
      "        \"\"\"Random sample of batch from replay buffer\"\"\"\n",
      "        experiences =  random.sample(self.memory, k=self.batch_size)\n",
      "        \n",
      "        #vstack: Stack arrays in sequence vertically (row wise)\n",
      "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
      "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(device)\n",
      "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
      "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
      "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
      "        \n",
      "        return (states, actions, rewards, next_states, dones)\n",
      "    \n",
      "    def __len__(self):\n",
      "        \"\"\"\"Size of internal memory\"\"\"\n",
      "        return len(self.memory)"
     ]
    }
   ],
   "source": [
    "! cat agent.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "\n",
    "#for training performance\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import deque\n",
    "from agent import Agent\n",
    "from unityagents import UnityEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpg(actor_weights_name, critic_weights_name, num_episodes=1500, max_t=1000, print_every=25):\n",
    "    \"\"\"Deep Deterministic Policy Gradient\n",
    "    \"\"\"\n",
    "    #empty list for score storing\n",
    "    mean_scores = [] \n",
    "    #empty list for moving average\n",
    "    moving_avgs = [] \n",
    "    best_score = -np.inf\n",
    "    scores_window = deque(maxlen=100) \n",
    "    #iterate over number of episodes defined\n",
    "    for episode in range(1, num_episodes + 1):\n",
    "        #reset enviroment\n",
    "        env_info = env.reset(train_mode=True)[brain_name] \n",
    "        #state of observations\n",
    "        states = env_info.vector_observations \n",
    "        #set score to zero to number of agents\n",
    "        scores = np.zeros(num_agents)\n",
    "        #from agent script: reset\n",
    "        agent.reset()\n",
    "        #keep track of time\n",
    "        start_time = time.time()\n",
    "        for t in range(max_t):\n",
    "            #pick according to state\n",
    "            actions = agent.act(states) \n",
    "            #make decision according to actions\n",
    "            env_info = env.step(actions)[brain_name]  \n",
    "            next_states = env_info.vector_observations \n",
    "            #get rewards\n",
    "            rewards = env_info.rewards \n",
    "            #check for finished episode\n",
    "            dones = env_info.local_done \n",
    "            #learn (from agent fucntion)\n",
    "            for state, action, reward, next_state, done in zip(states, actions, rewards, next_states, dones):\n",
    "                agent.step(state, action, reward, next_state, done, t)\n",
    "            states = next_states\n",
    "            scores += rewards\n",
    "            #when done break\n",
    "            if np.any(dones):\n",
    "                break\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        #append mean score\n",
    "        mean_scores.append(np.mean(scores)) \n",
    "        scores_window.append(mean_scores[-1]) \n",
    "        moving_avgs.append(np.mean(scores_window))\n",
    "        \n",
    "        if episode % print_every == 0:\n",
    "            print(\"\\rEpisode {} ({}s)\\tMean: {:.1f}\\tMoving Avg: {:.1f}\"\\\n",
    "                  .format(episode, round(duration), mean_scores[-1], moving_avgs[-1]))\n",
    "        if moving_avgs[-1] >= 30.0:\n",
    "            print(\"\\nEnvironment solved in {:d} episodes.\\tAverage score: {:.2f}\"\\\n",
    "                 .format(episode, moving_avgs[-1]))\n",
    "            torch.save(agent.actor_local.state_dict(), actor_weights_name)\n",
    "            torch.save(agent.critic_local.state_dict(), critic_weights_name)\n",
    "            break\n",
    "            \n",
    "    return(mean_scores, moving_avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size=state_size, action_size=action_size, seed=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 50 (10s)\tMean: 0.5\tMoving Avg: 1.0\n",
      "Episode 100 (12s)\tMean: 0.1\tMoving Avg: 0.7\n",
      "Episode 150 (12s)\tMean: 0.4\tMoving Avg: 0.3\n",
      "Episode 200 (13s)\tMean: 0.0\tMoving Avg: 0.3\n",
      "Episode 250 (10s)\tMean: 0.2\tMoving Avg: 0.7\n",
      "Episode 300 (10s)\tMean: 2.0\tMoving Avg: 1.3\n",
      "Episode 350 (10s)\tMean: 1.1\tMoving Avg: 1.6\n",
      "Episode 400 (13s)\tMean: 3.9\tMoving Avg: 2.1\n",
      "Episode 450 (10s)\tMean: 5.5\tMoving Avg: 2.9\n",
      "Episode 500 (10s)\tMean: 3.8\tMoving Avg: 3.8\n",
      "Episode 550 (10s)\tMean: 12.2\tMoving Avg: 6.2\n",
      "Episode 600 (10s)\tMean: 17.9\tMoving Avg: 11.3\n",
      "Episode 650 (11s)\tMean: 23.0\tMoving Avg: 16.8\n",
      "Episode 700 (14s)\tMean: 26.5\tMoving Avg: 20.5\n",
      "Episode 750 (12s)\tMean: 33.8\tMoving Avg: 24.2\n",
      "Episode 800 (10s)\tMean: 37.7\tMoving Avg: 29.1\n",
      "\n",
      "Environment solved in 810 episodes.\tAverage score: 30.03\n"
     ]
    }
   ],
   "source": [
    "scores, avgs = ddpg(actor_weights_name ='actor_single.pth', critic_weights_name='critic_single.pth', print_every=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(scores)), scores, label='DDPG')\n",
    "plt.plot(np.arange(len(scores)), avgs, c='r', label='moving average')\n",
    "plt.title(\"Mean score by episode\")\n",
    "plt.ylabel('Mean Score')\n",
    "plt.xlabel('Episode')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work:\n",
    "* Even though Gamma value pretty high, we might be able to increase a little bit more.\n",
    "* Decresing the learning interval or increasing the steps when learning might yield to faster results, also changing the Actor and Critic architecture.\n",
    "* Finally by adding prioritized experience replay as [(Hou & Zhang, 2017)](https://cardwing.github.io/files/RL_course_report.pdf)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
